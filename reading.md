# What I'm reading

## 2025-10

- **Empire of AI: Inside the reckless race for total domination**, Karen Jao, 2025<br> <br>
  A perfect complement to *Code Dependent* (see below), telling the other side of the story: a biography of OpenAI that illustrates how the oppression felt by people across the world arises from Silicon Valley. Ego, financial interests, ideological hubris and an attitude of empire-building - along with the huge capital available in Silicon Valley - enabled a small handful of people to develop large language models without the safety checks or ethical considerations that are usually expected of such new technologies. Like Murgia's message, Hao ends with a call for those affected by AI technologies to be included in its development from the start.<br> <br>
  *Tags:* ai-ethics<br>

## 2025-09

- **A neural manifold view of the brain**, Perich et al. (2025), Nature Neuroscience ([link](https://rdcu.be/ex8hW))<br> <br>
  An accessible and comprehensive overview of one of the topics that made me excited to study neuroscience (when I read Miguel Nicolelis's book *Beyond Boundaries*, long before my PhD). The authors make a convincing argument that neural manifolds solve the tricky problem of what to do with all the data we can now record thanks to recent developments in neurophysiological recording technologies: they offer a human-interpretable link between large amounts of low-level data and abstracted phenomena such as behaviour.<br> <br>
  *Tags:* computational-neuroscience<br>

## 2025-08

- **Code Dependent: Living in the Shadow of AI**, Madhumita Murgia, 2025<br> <br>
  A thoughful and balanced book telling human stories about the good and bad side of AI, from data annotators to under-resourced doctors to the parents of troubled teenagers: some using AI, some helping to develop it, some subjected to it, and some fighting back. A few of the tales are familiar ones that are often repeated in the increasing number of books about AI ethics, but Murgia's deliberate focus on collecting a global distribution of perspectives emphasises how, despite the potential for AI to improve people's lives across the world, it is often used as a tool to oppress by governments and enterprises alike.<br> <br>
  *Tags:* ai-ethics<br>
  

- **Beyond the Supply Chain: Artificial Intelligence's Demand Side**, Alicia Solow-Niederman, SSRN ([link](https://substack.com/redirect/921e88e8-992f-4061-bcbb-473884a8fbcc?j=eyJ1IjoiZTFpenIifQ.tj7HWegqye0jV0E0dW3m6Db6gT7WqPK7DVM9mUQAfgY))<br> <br>
  Found via Luiza Jarovsky's [AI governance newsletter](https://www.luizasnewsletter.com/).<br> <br>
  Solow-Niederman highlights some privacy issues that can arise via the (often innocent) interaction between a user and a generative AI system, which she argues are often overlooked. For example, a user asked a chatbot to generate some code, ChatGPT generated a URL, and the URL happened to lead to a real photo of a person's face on imgur. I recall (and now can't find) a social media post from some months ago in which people asked ChatGPT (with "memory" enabled, such that it had access to a large volume of chats from the same user) where in the world it thought they were from and what it thought their native language was, and users reported pretty high accuracy. Is the way you speak to AI a privacy violation by itself?<br> <br>
  *Tags:* ai-governance




